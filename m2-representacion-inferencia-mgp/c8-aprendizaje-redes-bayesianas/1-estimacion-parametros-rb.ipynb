{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimación de parámetros en redes Bayesianas\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/d/d5/Hey_Machine_Learning_Logo.png\" width=\"400px\" height=\"400px\" />\n",
    "\n",
    "> Hasta este momento hemos supuesto que ya conocemos nuestro modelo gráfico (incluyendo estructura y parámetros). Sin embargo, como deben sospechar, este no es el caso en problemas reales.\n",
    ">\n",
    "> Una manera de obtener un modelo gráfico es extraer tanto la red como los parámetros con la ayuda de un experto. Esta es una tarea no menor, y puede requerir muchísimo trabajo (semanas, quizá meses, dependiendo del tamaño de la red). Además, el acceso exhaustivo a un experto, puede no ser una suposición plausible.\n",
    ">\n",
    "> Por otra parte, es una suposición más común tener acceso a un conjunto de datos generados por la distribución (situación) que queremos modelar. Así, en esta clase nos enfocaremos en construir un modelo a partir de un conjunto de datos.\n",
    "\n",
    "> **Objetivos:**\n",
    "> - Describir el problema de aprendizaje de modelos.\n",
    "> - Obtener los parámetros de máxima verosimilitud para redes Bayesianas.\n",
    "> - Obtener los parámetros MAP para redes Bayesianas.\n",
    "\n",
    "> **Referencias:**\n",
    "> - Probabilistic Graphical Models: Principles and Techniques, By Daphne Koller and Nir Friedman. Ch. 17.\n",
    "> - Mastering Probabilistic Graphical Models Using Python, By Ankur Ankan and Abinash Panda. Ch. 5.\n",
    "\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://upload.wikimedia.org/wikipedia/commons/d/d5/Hey_Machine_Learning_Logo.png.</p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción al aprendizaje de modelos gráficos\n",
    "\n",
    "El proceso completo de aprendizaje puede ser resumido con el siguiente diagrama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"figures/pgm_construction.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Por qué quisieramos aprender un modelo gráfico?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Para responder preguntas desde una perspectiva probabilística al rededor de nuevas observaciones.\n",
    "\n",
    "¿Qué optimizaremos? **Verosimilitud de datos de entrenamiento**\n",
    "\n",
    "$$P(\\mathcal{D} | \\mathcal{M}).$$\n",
    "\n",
    "- Si un modelo hace que los datos sean más probables, entonces es plausible que los datos provengan de dicho modelo.\n",
    "\n",
    "Por otra parte, nos interesa evaluar este modelo sobre datos nuevos, no sobre datos que ya hayamos visto.\n",
    "\n",
    "- De manera que evaluamos el modelo sobre un conjunto separado de pruebas: **Verosimilitud de datos de prueba**\n",
    "  \n",
    "  $$P(\\mathcal{D}' | \\mathcal{M}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Para realizar una tarea de predicción específica sobre nuevas instancias.\n",
    "\n",
    "En este sentido, queremos predecir variables objetivo $\\bar{y}$ a partir de ciertas variables observadas $\\bar{x}$.\n",
    "\n",
    "¿Qué optimizamos? Un objetivo especializado: **recall, f1, ...**\n",
    "\n",
    "- Sin embargo, desde un punto de vista matemático y algorítmico, nos conviene optimizar la verosimilitud de datos de entrenamiento:\n",
    "  \n",
    "  $$P(\\mathcal{D} | \\mathcal{M}) = \\prod_{m} P(\\bar{y}[m] | \\bar{x}[m] : \\mathcal{M}).$$\n",
    "  \n",
    "Finalmente, el modelo debe ser evaluado sobre los **datos de prueba** y el **objetivo original especializado**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Para descubrir conocimiento acerca de $\\mathcal{M}^*$.\n",
    "\n",
    "En este caso, quisiéramos:\n",
    "\n",
    "- Entender dependencias directas entre variables (arcos).\n",
    "- Aprender la direccionalidad de los arcos.\n",
    "  \n",
    "¿Qué optimizaremos? **Verosimilitud de datos de entrenamiento**\n",
    "\n",
    "- Muy conveniente matemáticamente, pero...\n",
    "- Mala representación de precisión estructural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo prevenimos el overfitting?\n",
    "\n",
    "1. Si seleccionamos el modelo $\\mathcal{M}$ optimizando de acuerdo a la verosimilitud de entrenamiento, es bastante probable que caigamos en sobreajustar al ruido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. En parámetros:\n",
    "   - Los parámetros se ajustarán a la incertidumbre de los datos de entrenamiento.\n",
    "   - Solución: usar regularización, o equivalentemente, previas sobre los parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. En la estructura:\n",
    "   - Verosimilitud de entrenamiento siempre beneficia a las estructuras más complejas.\n",
    "   - Solución: penalizar la complejidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Parámetros de máxima verosimilitud en redes Bayesianas\n",
    "\n",
    "**Recordar parámetros de máxima verosimilitud en distribuciones multinomiales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquemos el principio de máxima verosimilitud para estimar los parámetros en una red Bayesiana.\n",
    "\n",
    "Supongamos que tenemos un conjunto de muestras iid de la red Bayesiana $X \\to Y$:\n",
    "\n",
    "$$\\mathcal{D} = \\{(x[1], y[1]), (x[2], y[2]), \\dots, (x[M], y[M])\\}$$\n",
    "\n",
    "Podemos dar una interpretación a estas muestras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"figures/iid_bn.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, tenemos los parámetros de la cpd de $X$, que denotamos como $\\theta_X$, y los parámetros de la cpd de $Y$, que denotamos como $\\theta_{Y|X}$. Denotaremos a todos los parámetros como $\\theta$.\n",
    "\n",
    "La función de verosimilitud es (<font color = red>ver en el pizarrón</font>):\n",
    "\n",
    "<!--\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\Theta : \\mathcal{D}) & = \\prod_{d=1}^{M} P(x[d], y[d] | \\Theta) \\\\\n",
    "                                  & = \\prod_{d=1}^{M} P(x[d] | \\Theta) P(y[d] | x[d], \\Theta) \\\\\n",
    "                                  & = \\left(\\prod_{d=1}^{M} P(x[d] | \\Theta)\\right) \\left(\\prod_{d=1}^{M} P(y[d] | x[d], \\Theta)\\right) \\\\\n",
    "                                  & = \\underbrace{\\left(\\prod_{d=1}^{M} P(x[d] | \\theta_X)\\right)}_{\\text{local likelihood}} \\underbrace{\\left(\\prod_{d=1}^{M} P(y[d] | x[d], \\theta_{Y|X})\\right)}_{\\text{local likelihood}}\n",
    "\\end{align}\n",
    "$$\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto se puede generalizar a redes Bayesianas en general:\n",
    "\n",
    "<!--\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\Theta : \\mathcal{D}) & = \\prod_{d=1}^{M} P(\\bar{x}[d] | \\Theta) \\\\\n",
    "                                  & = \\prod_{d=1}^{M} \\prod_{i=1}^{n} P(x_i[d] | \\mathrm{Pa}x_i[d], \\Theta)  \\\\\n",
    "                                  & = \\prod_{i=1}^{n} \\underbrace{\\prod_{d=1}^{M} P(x_i[d] | \\mathrm{Pa}x_i[d], \\theta_{X_i|\\mathrm{Pa}X_i})}_{\\text{local likelihood } \\mathcal{L}_i(\\theta_{X_i|\\mathrm{Pa}X_i} : \\mathcal{D})}  \\\\\n",
    "                                  & = \\prod_{i=1}^{n} \\mathcal{L}_i(\\theta_{X_i|\\mathrm{Pa}X_i} : \\mathcal{D})\n",
    "\\end{align}\n",
    "$$\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, si los parámetros $\\theta_{X_i|\\mathrm{Pa}X_i}$ son disjuntos, entonces, las estimaciones de máxima verosimilitud se pueden llevar a cabo por separado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimadores de máxima verosimilitud para CPDs tabulares\n",
    "\n",
    "Usando lo anterior y considerando $\\bar{U}=\\mathrm{Pa}X$, la verosimilitud de los datos es:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\prod_{d=1}^{M} P(x[d] | \\bar{u}[d], \\theta_{X|\\bar{U}}) & = \\prod_{x \\in \\mathrm{Val}(X),\\bar{u} \\in \\mathrm{Val}(U)} \\prod_{d: x[d]=x, \\bar{u}[d]=\\bar{u}} \\underbrace{P(x[d] | \\bar{u}[d], \\theta_{X|\\bar{U}})}_{\\theta_{x|\\bar{u}}} \\\\\n",
    "& = \\prod_{x \\in \\mathrm{Val}(X),\\bar{u} \\in \\mathrm{Val}(U)} \\theta_{x | \\bar{u}}^{M(x,\\bar{u})},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde $M(x,\\bar{u})$ es el número de veces que la muestra $d$ es consistente con $x, \\bar{u}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando el mismo principio que con distribuciones multinomiales:\n",
    "\n",
    "$$\\hat{\\theta}_{x|\\bar{u}} = \\frac{M(x,\\bar{u})}{\\sum_{x'} M(x',\\bar{u})} = \\frac{M(x,\\bar{u})}{M(\\bar{u})},$$\n",
    "\n",
    "el estimador de máxima verosimilitud corresponde a la cantidad de muestras consistentes con $x,\\bar{u}$ entre el la cantidad de muestras consistentes con $\\bar{u}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Clasificador Naive Bayes para dataset de vino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar BayesianModel, pyplot, pandas, networkx, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantización de variables numéricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red Bayesiana\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train y test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPDs estimadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fragmentación y overfitting\n",
    "\n",
    "Tenemos que:\n",
    "\n",
    "$$\\hat{\\theta}_{x|\\bar{u}} = \\frac{M(x,\\bar{u})}{\\sum_{x'} M(x',\\bar{u})} = \\frac{M(x,\\bar{u})}{M(\\bar{u})}.$$\n",
    "\n",
    "- Notamos que el número de posibles asignaciones para $x, \\bar{u}$ crece exponencialmente con el tamaño de $|\\bar{U}|$.\n",
    "\n",
    "- De forma que, si $X$ tiene muchos nodos padres, habrá pocas instancias de $x, \\bar{u}$.\n",
    "\n",
    "- Esto nos conllevará a estimadores muy pobres de $\\hat{\\theta}_{x|\\bar{u}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fenómeno se llama **fragmentación**.\n",
    "\n",
    "Por tanto, cuando el conjunto de datos es limitado, es común obtener mejor generalización usando estructuras más simples **incluso cuando no son correctas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Parámetros MAP en redes Bayesianas\n",
    "\n",
    "El problema principal de máxima verosimilitud es su tendencia al overfitting en escenarios con datos limitados.\n",
    "\n",
    "- Supongamos que tiramos una moneda 10 veces, y resulta que cae $x^1$ 7 de las 10 tiradas. Entonces,\n",
    "\n",
    "  $$\\hat{\\theta}_{MLE} = 0.7$$\n",
    "  \n",
    "- Supongamos que tiramos una moneda 1000 veces, y resulta que cae $x^1$ 700 de las 1000 tiradas. Entonces,\n",
    "\n",
    "  $$\\hat{\\theta}_{MLE} = 0.7$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El estimador del segundo escenario es mucho más plausible que en el primero. Sin embargo, el principio de máxima verosimilitud no distingue entre ambos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paradigma Bayesiano:** Si tenemos incertidumbre de algo, entonces deberíamos tratar ese algo como variable aleatoria, sobre la cual tenemos una distribución, la cual actualizamos en el tiempo en tanto adquirimos más datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo este paradigma, los parámetros $\\theta$ serán variables aleatorias.\n",
    "\n",
    "- Dado $\\theta$, los tiros son independientes.\n",
    "\n",
    "- Si  $\\theta$ es desconocido, entonces los tiros no son independientes:\n",
    "  - Cada tiro nos dice algo acerca de $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En una distribución multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilidad conjunta:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x[1], \\dots, x[M], \\theta) & = P(x[1], \\dots, x[M] | \\theta) P(\\theta) \\\\\n",
    "                             & = P(\\theta) \\underbrace{\\prod_{d=1}^{M} P(x[d] | \\theta)}_{\\text{likelihood function}} \\\\\n",
    "                             & = P(\\theta)\\prod_{i=1}^{k} \\theta_k^{M_i}.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribución posterior:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(\\theta | x[1], \\dots, x[M]) & = \\frac{P(x[1], \\dots, x[M], \\theta)}{P(x[1], \\dots, x[M])} \\\\\n",
    "                              & \\propto P(x[1], \\dots, x[M], \\theta) \\\\\n",
    "                              & = P(\\theta)\\prod_{i=1}^{k} \\theta_k^{M_i}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previa: Distribution de Dirichlet (generalización de la distribución Beta)\n",
    "\n",
    "Si $X$ es una distribución multinomial sobre $k$ valores, una buena suposición para la distribución de los parámetros $\\bar{\\theta} = [\\theta_1, \\dots, \\theta_k]$ es la [**distribución de Dirichlet**](https://en.wikipedia.org/wiki/Dirichlet_distribution).\n",
    "\n",
    "$\\bar{\\theta} \\sim \\mathrm{Dir}(\\bar{\\alpha})$, donde $\\bar{\\alpha}=[\\alpha_1, \\dots, \\alpha_k]$,  si\n",
    "\n",
    "$$P(\\bar{\\theta}; \\bar{\\alpha}) = \\frac{1}{Z} \\prod_{i=1}^{k} \\theta_i^{\\alpha_i - 1},$$\n",
    "\n",
    "donde $\\sum_{i=1}^{k}\\theta_i=1$ y,\n",
    "\n",
    "$$Z = \\frac{\\prod_{i=1}^{k} \\Gamma(\\alpha_i)}{\\Gamma(\\sum_{i=1}^{k}\\alpha_i)},$$\n",
    "\n",
    "donde $\\Gamma(x)= \\int_{0}^{\\infty}t^{x-1}e^{-t} \\mathrm{d}t$ es una extensión continua del factorial.\n",
    "\n",
    "1. Media\n",
    "  \n",
    "   $$\n",
    "   \\mathbb{E}[\\theta_k] = \\frac{\\alpha_k}{\\sum_{j=1}^{k}\\alpha_j}\n",
    "   $$\n",
    "   \n",
    "2. Moda\n",
    "     \n",
    "   $$\n",
    "   \\text{Mode}[\\theta_k] = \\frac{\\alpha_k - 1}{\\sum_{j=1}^{k}\\alpha_j - K}\n",
    "   $$\n",
    "\n",
    "3. Varianza\n",
    "   \n",
    "   $$\n",
    "   \\text{Var}[\\theta_k] = \\frac{\\alpha_k (\\alpha_0 - \\alpha_k)}{\\alpha_0^2 (\\alpha_0 + 1)}\n",
    "   $$\n",
    "   \n",
    "4. Covarianza\n",
    "   \n",
    "   $$\n",
    "   \\text{Cov}[\\theta_k, \\theta_j] = \\frac{- \\alpha_k \\alpha_j}{\\alpha_0^2 (\\alpha_0 + 1)}, \\qquad \\text{para } j\\neq k\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intuitivamente, los hiperparámetros $\\alpha_i$ corresponden al número de muestras con valor $i$ que hemos visto anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución beta en scipy.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos varias distribuciones beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con la previa de Dirichlet, ¿Cómo es la posterior?\n",
    "\n",
    "- La función de verosimilitud es: $P(\\mathcal{D} | \\bar{\\theta}) = \\prod_{i=1}^{k} \\theta_i^{M_i}$.\n",
    "\n",
    "- La previa es: $P(\\bar{\\theta}) \\propto \\prod_{i=1}^{k} \\theta_i^{\\alpha_i - 1}$\n",
    "\n",
    "Entonces,\n",
    "\n",
    "$$\n",
    "P(\\bar{\\theta} | \\mathcal{D}) \\propto \\prod_{i=1}^{k} \\theta_i^{\\alpha_i + M_i - 1}.\n",
    "$$\n",
    "\n",
    "Esto es, una distribución de Dirichlet $(\\bar{\\theta} | \\mathcal{D}) \\sim \\mathrm{Dir}(\\alpha_1 + M_1, \\dots, \\alpha_k + M_k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En este sentido ...\n",
    "\n",
    "Antes de ver los datos:\n",
    "\n",
    "$$P(X=x^i | \\theta) = \\frac{\\alpha_i}{\\sum_{j=1}^{k}\\alpha_j} = \\frac{\\alpha_i}{\\alpha}.$$\n",
    "\n",
    "Después de ver los datos:\n",
    "\n",
    "$$P(X[M+1]=x^i | \\theta, x[1], \\dots, x[M]) = \\frac{\\alpha_i + M_i}{\\alpha + M}.$$\n",
    "\n",
    "\n",
    "- EL término $\\alpha=\\sum_{j=1}^{k}\\alpha_j$ se conoce como **equivalent sample size**.\n",
    "  - Un $\\alpha$ más grande significa que tenemos más certeza de nuestra previa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál es el efecto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random numbers form a Bernoulli distribution\n",
    "theta_true = 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain MLE estimation at each step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Bayesian estimation for different values of alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimadores MAP son menos sensibles al ruido en los datos.\n",
    "\n",
    "- Estimador MAP $\\to$ estimador de máxima verosimilitud cuando el número de muestras $\\to \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Así como extendimos las ideas de máxima verosimilitud de una distribución multinomial a redes Bayesianas, similarmente sucede con estimadores MAP.**\n",
    "\n",
    "Todos los detalles en *Probabilistic Graphical Models: Principles and Techniques, By Daphne Koller and Nir Friedman. Ch. 17.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Clasificador Naive Bayes para dataset de vino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos de nuevo el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos estimador bayesiano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimar CPDs con previa de Dirichlet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos CPDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anuncios\n",
    "\n",
    "## 1. Quiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
